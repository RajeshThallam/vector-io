{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76f6f215-269b-4ada-bf48-5ba0f3231e2c",
   "metadata": {},
   "source": [
    "# Quickstart for creating a Vertex Vector Search Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6ff27-e3ce-47cb-931b-66827016fddb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51486dd3-b9fd-4747-b67d-8fd66bc9e161",
   "metadata": {},
   "source": [
    "### pip installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f47fd1ec-78a3-4d39-9997-9079b0beefe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade --user google-cloud-aiplatform google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f20d33c-3458-4473-ae5e-e00e25183573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "# import time\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78076478-d69e-4816-be0a-34c0cc59838a",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa350be-d6db-4dd1-bc33-8213184a2cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "#python warning \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50eb5bb5-116e-43d1-8f51-86aede5a1405",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery SDK version      : 3.15.0\n",
      "Vertex AI SDK version     : 1.39.0\n",
      "Cloud Storage SDK version : 2.14.0\n"
     ]
    }
   ],
   "source": [
    "print(f'BigQuery SDK version      : {bigquery.__version__}')\n",
    "print(f'Vertex AI SDK version     : {aiplatform.__version__}')\n",
    "print(f'Cloud Storage SDK version : {storage.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ace3c-fc05-4d88-89c2-228c2865df4b",
   "metadata": {},
   "source": [
    "### Define vars and GCP env config\n",
    "\n",
    "`CREATE_NEW_ASSETS`\n",
    "* True creates new GCS buckets and Vector Search instances, etc.\n",
    "* False skips these steps (in case you need to re-run notebook to include new variables you create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef3881a-e0b2-4f91-9036-01a66a39507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new gcs bucket, vs index, etc.?\n",
    "CREATE_NEW_ASSETS         = False "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae8e5bf-364d-49b1-bc48-6725b9cbfaab",
   "metadata": {},
   "source": [
    "**Edit these to define naming conventions and stay organized across different versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28730dbe-9bca-4b7d-8e09-ca779522066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX = vvs-vectorio-vpc1\n"
     ]
    }
   ],
   "source": [
    "# naming convention for all cloud resources\n",
    "VERSION        = \"vpc1\"                        # TODO\n",
    "PREFIX         = f'vvs-vectorio-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7973084-b8cd-433f-96ba-a5728684de60",
   "metadata": {},
   "source": [
    "#### Edit these as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaad187e-e6ef-43a9-89aa-bb525a206462",
   "metadata": {},
   "source": [
    "`VPC_NETWORK_NAME`\n",
    "* if index will be **deployed to a private endpoint** within a VPC network, edit this with the name of your VPC network name\n",
    "* if index will be **deployed to a public endpoint**, leave blank\n",
    "\n",
    "> For details on configuring VPC for Vertex AI Vector Search, see **[Set up a VPC Network Peering connection](https://cloud.google.com/vertex-ai/docs/vector-search/setup/vpc)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef68899-8494-411f-901b-a693ed0a22c0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>⚠️ if deploying index to index endpoint within a VPC network, you must interact with the index endpoint from within the VPC network, i.e., run this notebook in a Vertex Workbench instance within that VPC ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de35ef8e-e64a-451b-a963-1cc8b74fdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VPC_NETWORK_NAME = \"ucaip-haystack-vpc-network\"  # e.g., \"your-vpc-name\" | \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dd8575e-13ee-4094-af90-067f05f59ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VPC_NETWORK_NAME     = ucaip-haystack-vpc-network\n",
      "USE_PUBLIC_ENDPOINTS = False\n"
     ]
    }
   ],
   "source": [
    "if VPC_NETWORK_NAME:\n",
    "    USE_PUBLIC_ENDPOINTS = False\n",
    "else:\n",
    "    USE_PUBLIC_ENDPOINTS = True\n",
    "    \n",
    "print(f\"VPC_NETWORK_NAME     = {VPC_NETWORK_NAME}\")\n",
    "print(f\"USE_PUBLIC_ENDPOINTS = {USE_PUBLIC_ENDPOINTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e408fff-cf90-4156-a6ac-ac59d04e2667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGION    = us-central1\n",
      "BQ_REGION = US\n"
     ]
    }
   ],
   "source": [
    "# locations / regions for cloud resources\n",
    "REGION            = 'us-central1'        \n",
    "BQ_REGION         = 'US'\n",
    "\n",
    "print(f\"REGION    = {REGION}\")\n",
    "print(f\"BQ_REGION = {BQ_REGION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4018f-f261-4d64-b851-d57861933ba1",
   "metadata": {},
   "source": [
    "#### Let these ride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65f4133a-3677-4352-b223-3c6794d02de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID       = hybrid-vertex\n",
      "PROJECT_NUM      = 934903580331\n",
      "VERTEX_SA        = 934903580331-compute@developer.gserviceaccount.com\n",
      "VPC_NETWORK_FULL = projects/934903580331/global/networks/ucaip-haystack-vpc-network\n",
      "BUCKET_NAME      = vvs-vectorio-vpc1-hybrid-vertex\n",
      "BUCKET_URI       = gs://vvs-vectorio-vpc1-hybrid-vertex\n"
     ]
    }
   ],
   "source": [
    "# let these ride\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "PROJECT_NUM              = !gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\n",
    "PROJECT_NUM              = PROJECT_NUM[0]\n",
    "\n",
    "# service account\n",
    "VERTEX_SA                = f'{PROJECT_NUM}-compute@developer.gserviceaccount.com'\n",
    "\n",
    "# full VPC network name\n",
    "VPC_NETWORK_FULL         = f\"projects/{PROJECT_NUM}/global/networks/{VPC_NETWORK_NAME}\"\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "print(f\"PROJECT_ID       = {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM      = {PROJECT_NUM}\")\n",
    "print(f\"VERTEX_SA        = {VERTEX_SA}\")\n",
    "print(f\"VPC_NETWORK_FULL = {VPC_NETWORK_FULL}\")\n",
    "print(f\"BUCKET_NAME      = {BUCKET_NAME}\")\n",
    "print(f\"BUCKET_URI       = {BUCKET_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f30dea40-40ea-466e-a1ce-ee8057619165",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b367f92-fb74-4479-b00d-6347722966c1",
   "metadata": {},
   "source": [
    "### Enable APIs, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4af9f3ff-37f5-44d1-8b7f-d0b67012facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud services enable compute.googleapis.com \\\n",
    "#                         aiplatform.googleapis.com \\\n",
    "#                         storage.googleapis.com \\\n",
    "#                         iam.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c55a7-c42e-4b4e-90c8-88ca006e561e",
   "metadata": {},
   "source": [
    "### Create GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56b2944b-e2e3-422a-9752-9810b83b6d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934903580331-compute@developer.gserviceaccount.com should have access to gs://vvs-vectorio-vpc1-hybrid-vertex\n"
     ]
    }
   ],
   "source": [
    "if CREATE_NEW_ASSETS:\n",
    "    \n",
    "    # create new bucket\n",
    "    ! gsutil mb -l $REGION $BUCKET_URI\n",
    "    \n",
    "    ### give Service account Admin to GCS\n",
    "    !gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "        --member=serviceAccount:$VERTEX_SA \\\n",
    "        --role=roles/storage.admin\n",
    "    \n",
    "    ### uncomment if org policy prevents granting Admin:\n",
    "    # ! gsutil iam ch serviceAccount:{$VERTEX_SA}:roles/storage.objects.get $BUCKET_URI\n",
    "    # ! gsutil iam ch serviceAccount:{$VERTEX_SA}:roles/storage.objects.create $BUCKET_URI\n",
    "    # ! gsutil iam ch serviceAccount:{$VERTEX_SA}:roles/storage.objects.list $BUCKET_URI\n",
    "    \n",
    "    \n",
    "print(f\"{VERTEX_SA} should have access to {BUCKET_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde75602-121f-4ce1-a416-34d810d32383",
   "metadata": {},
   "source": [
    "### Save notebook config \n",
    "\n",
    "> to easily use in other GCP related notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ce416aa-7d10-4ac0-94ba-44b0fcb87571",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREFIX                   = \"vvs-vectorio-vpc1\"\n",
      "VERSION                  = \"vpc1\"\n",
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_REGION                = \"US\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "USE_PUBLIC_ENDPOINTS     = \"False\"\n",
      "\n",
      "BUCKET_NAME              = \"vvs-vectorio-vpc1-hybrid-vertex\"\n",
      "BUCKET_URI               = \"gs://vvs-vectorio-vpc1-hybrid-vertex\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = f\"\"\"\n",
    "PREFIX                   = \\\"{PREFIX}\\\"\n",
    "VERSION                  = \\\"{VERSION}\\\"\n",
    "\n",
    "PROJECT_ID               = \\\"{PROJECT_ID}\\\"\n",
    "PROJECT_NUM              = \\\"{PROJECT_NUM}\\\"\n",
    "\n",
    "REGION                   = \\\"{REGION}\\\"\n",
    "BQ_REGION                = \\\"{BQ_REGION}\\\"\n",
    "\n",
    "VERTEX_SA                = \\\"{VERTEX_SA}\\\"\n",
    "\n",
    "VPC_NETWORK_NAME         = \\\"{VPC_NETWORK_NAME}\\\"\n",
    "VPC_NETWORK_FULL         = \\\"{VPC_NETWORK_FULL}\\\"\n",
    "\n",
    "USE_PUBLIC_ENDPOINTS     = \\\"{USE_PUBLIC_ENDPOINTS}\\\"\n",
    "\n",
    "BUCKET_NAME              = \\\"{BUCKET_NAME}\\\"\n",
    "BUCKET_URI               = \\\"{BUCKET_URI}\\\"\n",
    "\"\"\"\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d54aa565-eebd-4b6d-8008-21a6c2c369dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying from <STDIN>...\n",
      "/ [1 files][    0.0 B/    0.0 B]                                                \n",
      "Operation completed over 1 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "!echo '{config}' | gsutil cp - {BUCKET_URI}/config/notebook_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3828350-76f1-4a22-b331-39867c9c8431",
   "metadata": {},
   "source": [
    "### Initialize Google Cloud SDK Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93b65a4c-4b73-47d2-b488-3ca64242cad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "# bigquery client\n",
    "bq_client = bigquery.Client(\n",
    "    project=PROJECT_ID,\n",
    "    # location=BQ_REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e8a43-a4e2-4967-9f16-54e0aff92e38",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare StackOverflow data\n",
    "You use the [Stack Overflow dataset](https://console.cloud.google.com/marketplace/product/stack-exchange/stack-overflow) of question and answers hosted on BigQuery.\n",
    "\n",
    "> This public dataset is hosted in Google BigQuery and is included in BigQuery's 1TB/mo of free tier processing. This means that each user receives 1TB of free BigQuery processing every month, which can be used to run queries on this public dataset.\n",
    "\n",
    "The BigQuery table is too large to fit into memory, so you need to write a generator called `query_bigquery_chunks` to yield chunks of the dataframe for processing. Additionally, an extra column `title_with_body` is added, which is a concatenation of the question title and body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f229757d-9c13-4d3b-8603-d154f28c9a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Any, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7112765e-01b3-45a1-abd3-8615220ce23a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# QUERY_TEMPLATE = \"\"\"\n",
    "#         SELECT distinct q.id, \n",
    "#             q.title, \n",
    "#             q.body\n",
    "#         FROM (\n",
    "#             SELECT * FROM `bigquery-public-data.stackoverflow.posts_questions` \n",
    "#             WHERE Score > 0 \n",
    "#             ORDER BY View_Count desc\n",
    "#             ) AS q \n",
    "#         LIMIT {limit} OFFSET {offset};\n",
    "#         \"\"\"\n",
    "\n",
    "QUERY_TEMPLATE = \"\"\"\n",
    "        SELECT DISTINCT q.id, \n",
    "           q.title, \n",
    "           q.body, \n",
    "           q.score, \n",
    "           q.tags,\n",
    "        FROM (\n",
    "            SELECT * FROM `bigquery-public-data.stackoverflow.posts_questions` \n",
    "            WHERE score > 0 \n",
    "            ORDER BY view_count DESC\n",
    "            ) AS q \n",
    "        LIMIT {limit} OFFSET {offset};\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "def query_bigquery_chunks(\n",
    "    max_rows: int, \n",
    "    rows_per_chunk: int, \n",
    "    start_chunk: int = 0\n",
    ") -> Generator[pd.DataFrame, Any, None]:\n",
    "    \n",
    "    for offset in range(start_chunk, max_rows, rows_per_chunk):\n",
    "        query = QUERY_TEMPLATE.format(limit=rows_per_chunk, offset=offset)\n",
    "        query_job = bq_client.query(query)\n",
    "        rows = query_job.result()\n",
    "        df = rows.to_dataframe()\n",
    "        df[\"title_with_body\"] = df.title + \"\\n\" + df.body\n",
    "        df['tags_split'] = df['tags'].apply(lambda x: x.split('|', maxsplit=1)[0])\n",
    "        yield df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b7f536e-de44-4f49-9e6a-c67ef627369a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>tags</th>\n",
       "      <th>title_with_body</th>\n",
       "      <th>tags_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62387396</td>\n",
       "      <td>Unable install SQLserver tool in ubuntu 20</td>\n",
       "      <td>&lt;p&gt;I installed SQLserver in my ubuntu. But whe...</td>\n",
       "      <td>11</td>\n",
       "      <td>sql-server|bash|ubuntu|installation</td>\n",
       "      <td>Unable install SQLserver tool in ubuntu 20\\n&lt;p...</td>\n",
       "      <td>sql-server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60270794</td>\n",
       "      <td>Vue 3 composition API, how to get context pare...</td>\n",
       "      <td>&lt;p&gt;I'm running into an issue with Vue 3 (alpha...</td>\n",
       "      <td>16</td>\n",
       "      <td>vue.js|vuejs3|vue-composition-api</td>\n",
       "      <td>Vue 3 composition API, how to get context pare...</td>\n",
       "      <td>vue.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49413937</td>\n",
       "      <td>Why TypeError: axios.create is not a function?...</td>\n",
       "      <td>&lt;p&gt;I'm trying to test my axios API functions i...</td>\n",
       "      <td>13</td>\n",
       "      <td>unit-testing|testing|axios|axios-mock-adapter</td>\n",
       "      <td>Why TypeError: axios.create is not a function?...</td>\n",
       "      <td>unit-testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49665571</td>\n",
       "      <td>[Vue warn]: Unknown custom element: &lt;nuxt-link...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;I'm using ...</td>\n",
       "      <td>31</td>\n",
       "      <td>vue.js|jestjs|vue-router|nuxt.js|vue-test-utils</td>\n",
       "      <td>[Vue warn]: Unknown custom element: &lt;nuxt-link...</td>\n",
       "      <td>vue.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44971694</td>\n",
       "      <td>How to use `jsonb_set` on column with null values</td>\n",
       "      <td>&lt;p&gt;I am using Postgres 9.6 and I have a JSONB ...</td>\n",
       "      <td>15</td>\n",
       "      <td>json|postgresql|jsonb|postgresql-9.6</td>\n",
       "      <td>How to use `jsonb_set` on column with null val...</td>\n",
       "      <td>json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  62387396         Unable install SQLserver tool in ubuntu 20   \n",
       "1  60270794  Vue 3 composition API, how to get context pare...   \n",
       "2  49413937  Why TypeError: axios.create is not a function?...   \n",
       "3  49665571  [Vue warn]: Unknown custom element: <nuxt-link...   \n",
       "4  44971694  How to use `jsonb_set` on column with null values   \n",
       "\n",
       "                                                body  score  \\\n",
       "0  <p>I installed SQLserver in my ubuntu. But whe...     11   \n",
       "1  <p>I'm running into an issue with Vue 3 (alpha...     16   \n",
       "2  <p>I'm trying to test my axios API functions i...     13   \n",
       "3  <p><strong>Problem</strong></p>\\n<p>I'm using ...     31   \n",
       "4  <p>I am using Postgres 9.6 and I have a JSONB ...     15   \n",
       "\n",
       "                                              tags  \\\n",
       "0              sql-server|bash|ubuntu|installation   \n",
       "1                vue.js|vuejs3|vue-composition-api   \n",
       "2    unit-testing|testing|axios|axios-mock-adapter   \n",
       "3  vue.js|jestjs|vue-router|nuxt.js|vue-test-utils   \n",
       "4             json|postgresql|jsonb|postgresql-9.6   \n",
       "\n",
       "                                     title_with_body    tags_split  \n",
       "0  Unable install SQLserver tool in ubuntu 20\\n<p...    sql-server  \n",
       "1  Vue 3 composition API, how to get context pare...        vue.js  \n",
       "2  Why TypeError: axios.create is not a function?...  unit-testing  \n",
       "3  [Vue warn]: Unknown custom element: <nuxt-link...        vue.js  \n",
       "4  How to use `jsonb_set` on column with null val...          json  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a dataframe of 1000 rows for demonstration purposes\n",
    "df_test = next(\n",
    "    query_bigquery_chunks(\n",
    "        max_rows=1000, \n",
    "        rows_per_chunk=1000\n",
    "    )\n",
    ")\n",
    "\n",
    "# Examine the data\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d9aa031-5457-4ace-a0d4-bd3dcf05647f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 7)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e0436-3cc7-48cf-9280-5a58fd2ef87c",
   "metadata": {},
   "source": [
    "## Instantiate the text encoding model\n",
    "\n",
    "> Use the [Vertex AI Embeddings for Text API](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings) developed by Google for converting text to embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e7c9e1-3fb1-44c0-b466-82bb7a97ab97",
   "metadata": {},
   "source": [
    "### Define helper functions\n",
    "\n",
    "* `encode_texts_to_embeddings()`: convert sentences to embeddings\n",
    "\n",
    "* `generate_batches()`: splits sentences into batches of 5 before sending to the embedding API\n",
    "\n",
    "* `encode_text_to_embedding_batched()`: calls `generate_batches()` to handle batching, calls embedding API via `encode_texts_to_embeddings()`, handles rate-limiting using `time.sleep` *(Note: For production use cases, use more sophisticated rate-limiting mechanism that takes retries into account)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "900099e4-ac26-4b3a-8fda-22491b01235c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0413818a-09a0-4114-b94c-df2ee104779c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "# Load the \"Vertex AI Embeddings for Text\" model\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "\n",
    "\n",
    "# Define an embedding method that uses the model\n",
    "def encode_texts_to_embeddings(sentences: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        embeddings = model.get_embeddings(sentences)\n",
    "        return [embedding.values for embedding in embeddings]\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(sentences))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dc5c3a9-29ee-45af-88ba-b01df08a93d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Generator, List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Generator function to yield batches of sentences\n",
    "def generate_batches(\n",
    "    sentences: List[str], \n",
    "    batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        yield sentences[i : i + batch_size]\n",
    "\n",
    "\n",
    "def encode_text_to_embedding_batched(\n",
    "    sentences: List[str], \n",
    "    api_calls_per_second: int = 10, \n",
    "    batch_size: int = 5\n",
    ") -> Tuple[List[bool], np.ndarray]:\n",
    "\n",
    "    embeddings_list: List[List[float]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(sentences, batch_size)\n",
    "\n",
    "    seconds_per_job = 1 / api_calls_per_second\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(\n",
    "            batches, total=math.ceil(len(sentences) / batch_size), position=0\n",
    "        ):\n",
    "            futures.append(\n",
    "                executor.submit(functools.partial(encode_texts_to_embeddings), batch)\n",
    "            )\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "\n",
    "    is_successful = [\n",
    "        embedding is not None for sentence, embedding in zip(sentences, embeddings_list)\n",
    "    ]\n",
    "    embeddings_list_successful = np.squeeze(\n",
    "        np.stack([embedding for embedding in embeddings_list if embedding is not None])\n",
    "    )\n",
    "    return is_successful, embeddings_list_successful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffddc20-68b0-454a-a7cd-81b3a27be57f",
   "metadata": {},
   "source": [
    "*test encoding function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9508a3b8-456e-47e5-b049-9840e8a97244",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db753723cbd34cdbafe3486a0e2507d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode a subset of questions for validation\n",
    "questions = df_test.title.tolist()[:500]\n",
    "\n",
    "is_successful, question_embeddings = encode_text_to_embedding_batched(\n",
    "    sentences=df.title.tolist()[:500],\n",
    ")\n",
    "\n",
    "# Filter for successfully embedded sentences\n",
    "questions = np.array(questions)[is_successful]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33957031-69c2-4248-a6d2-f44c348eeec9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Unable install SQLserver tool in ubuntu 20'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(questions.shape)\n",
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f10b7dca-3a2e-4885-826f-9c55bb5619c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 768)\n"
     ]
    }
   ],
   "source": [
    "print(question_embeddings.shape)\n",
    "# question_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e927ceee-5aba-4bf2-81d5-966f57109d11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(is_successful)\n",
    "is_successful[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8381de28-a89b-4967-bce7-0efa2d9de703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sentences=df.title.tolist()[:10]\n",
    "\n",
    "# batches_test = generate_batches(sentences, batch_size=5)\n",
    "# next(batches_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32e0fe28-c865-4e5c-8e8f-af24490d59f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "DIMENSIONS = len(question_embeddings[0])\n",
    "\n",
    "print(DIMENSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c551d0d6-57cb-4d0e-a118-a483ca52b6a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query question = Locust/Python: Splitting a tasks array with if conditions in a SequentialTaskSet\n",
      "\t0: Locust/Python: Splitting a tasks array with if conditions in a SequentialTaskSet: 0.9999988941994281\n",
      "\t1: Python: Find specific and distinct set of combinations: 0.690856257416196\n",
      "\t2: Aysnc convert object to coroutine. Load object fields: 0.6770379306583949\n",
      "\t3: How to loop through an array and find matches with the values in the array: 0.6720070304466261\n",
      "\t4: How to remove stop words and lemmatize at the same time when using spaCy?: 0.661894678735283\n",
      "\t5: Using graphql, I need to crate a mutation which includes an empty array: 0.6467180591503121\n",
      "\t6: json array into json array - Python: 0.6453590036206271\n",
      "\t7: Learing of if and else: 0.6427257821148757\n",
      "\t8: iterative append previous value in python: 0.6377486452871857\n",
      "\t9: PHP - curl_multi_exec while loop uses 100% of the CPU: 0.636539320971094\n",
      "\t10: Convert string to dict without using split in Python Scrapy: 0.6358473515641552\n",
      "\t11: How to sort a group of elements using jquery sortable and prevent a spot from being placed: 0.6352685479479534\n",
      "\t12: Error in writing a backtracking solver for sudoku: 0.6349433643590245\n",
      "\t13: I would like to count matching neighboring items in an array and return the count: 0.6345915059233709\n",
      "\t14: How to print serial data into label in python?: 0.6343306586445848\n",
      "\t15: Indentation management in ANTLR4 for a python interpreter: 0.6330389883466464\n",
      "\t16: Using nested if or ifelse in Netlogo to specify probabilities: 0.6321876524811041\n",
      "\t17: model.fit_generator: Error when checking target: expected lambda_2 to have 4 dimensions, but got array with shape (200, 1): 0.6319575496224799\n",
      "\t18: Labelling duplicates in PySpark: 0.631235566135572\n",
      "\t19: Generating foreign based query sets: 0.6306545406490516\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "question_index = random.randint(0, 99)\n",
    "\n",
    "print(f\"Query question = {questions[question_index]}\")\n",
    "\n",
    "# Get similarity scores for each embedding by using dot-product.\n",
    "scores = np.dot(question_embeddings[question_index], question_embeddings.T)\n",
    "\n",
    "# Print top 20 matches\n",
    "for index, (question, score) in enumerate(\n",
    "    sorted(zip(questions, scores), key=lambda x: x[1], reverse=True)[:20]\n",
    "):\n",
    "    print(f\"\\t{index}: {question}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a1c1a4b1-afbb-4312-a4fd-4403ece2c42b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings directory: /var/tmp/tmppkzjydtx\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "embeddings_file_path = Path(tempfile.mkdtemp())\n",
    "\n",
    "print(f\"Embeddings directory: {embeddings_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc756d91-0d45-4cb8-b0c4-008bb6642b7a",
   "metadata": {},
   "source": [
    "### formatting vectors for Vertex Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd582f-a176-4118-af81-9b9886c9eb57",
   "metadata": {},
   "source": [
    "**embedding_vector**\n",
    "* Encode the file using UTF-8.\n",
    "* Make each line a valid `.json` object to be interpreted as a record.\n",
    "* Include in each record a field named `id` that requires a valid UTF-8 string that is the ID of the vector.\n",
    "* Include in each record a field named embedding that requires an array of numbers. This is the feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00273b6-6cba-4fff-a990-df3fbff106ab",
   "metadata": {},
   "source": [
    "Filtering with **String Namespaces**\n",
    "\n",
    "The value of the field `restricts`, if present, should be an array of objects, each is turned into a TokenNamespace in restricts.\n",
    "\n",
    "For each vector's record, add a field called restricts, to contain an array of objects, each of which is a namespace.\n",
    "\n",
    "* Each object must have a field named namespace. This field is the TokenNamespace.namespace, namespace.\n",
    "* The value of the field allow, if present, is an array of strings. This array of strings is the TokenNamespace.string_tokens list.\n",
    "* The value of the field deny, if present, is an array of strings. This array of strings is the TokenNamespace.string_denylist_tokens list.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"id\": \"42\", \n",
    "    \"embedding\": [0.5, 1.0], \n",
    "    \"restricts\": [\n",
    "        {\"namespace\": \"class\",\"allow\": [\"cat\", \"pet\"]},\n",
    "        {\"namespace\": \"category\", \"allow\": [\"feline\"]}\n",
    "    ]\n",
    "}\n",
    "{\n",
    "    \"id\": \"43\", \n",
    "    \"embedding\": [0.6, 1.0], \n",
    "    \"restricts\": [\n",
    "        {\"namespace\": \"class\", \"allow\": [\"dog\", \"pet\"]},\n",
    "        {\"namespace\": \"category\", \"allow\": [\"canine\"]}\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a882c77b-0c45-4944-84f7-cff5199a1a85",
   "metadata": {},
   "source": [
    "Filtering with **Numeric namespaces**\n",
    "For each vector's record, add a field called `numeric_restricts`, to contain an array of objects, each of which is a numeric restrict.\n",
    "\n",
    "* Each object must have a field named namespace. This field is the NumericRestrictNamespace.namespace, namespace.\n",
    "* Each object must have one of `value_int`, `value_float`, and `value_double`.\n",
    "* Each object must not have a field named op. This field is only for query.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"id\": \"42\", \n",
    "    \"embedding\": [0.5, 1.0], \n",
    "    \"numeric_restricts\": [\n",
    "        {\"namespace\": \"size\", \"value_int\": 3},\n",
    "        {\"namespace\": \"ratio\", \"value_float\": 0.1}\n",
    "    ]\n",
    "}\n",
    "{\n",
    "    \"id\": \"43\", \n",
    "    \"embedding\": [0.6, 1.0], \n",
    "    \"numeric_restricts\": [\n",
    "        {\"namespace\":\"weight\", \"value_double\": 0.3}\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a26ba3-62b6-4d34-b6d5-c17c668e5f4d",
   "metadata": {},
   "source": [
    "**crowding tag**\n",
    "\n",
    "The value of the field `crowding_tag`, if present, should be a string\n",
    "\n",
    "```\n",
    "{\n",
    "    \"id\": \"43\", \n",
    "    \"embedding\": [0.6, 1.0], \n",
    "    \"numeric_restricts\": [\n",
    "        {\"namespace\":\"weight\", \"value_double\": 0.3}\n",
    "    ],\n",
    "    \"crowding_tag\": \"shoes\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8038bd7a-6feb-4c93-8078-b1453abe0bab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(len(question_embeddings))\n",
    "# question_embeddings[0]\n",
    "\n",
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "631dc39c-7926-4076-8127-d53b45e81784",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BQ_NUM_ROWS          : 1000\n",
      "BQ_CHUNK_SIZE        : 100\n",
      "BQ_NUM_CHUNKS        : 10\n",
      "API_CALLS_PER_SECOND : 5.0\n",
      "ITEMS_PER_REQUEST    : 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787a1e99467743f2a8b62282414c4cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunk of rows from BigQuery:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: 0 of 10 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd96707a120489aa119147b0b3e3c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags_chunk                : 100\n",
      "scores_chunk              : 100\n",
      "question_chunk_embeddings : 100\n",
      "id_chunk[is_successful]   : 100\n",
      "Starting: 1 of 10 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786d7c57a150412181662ce2814660e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags_chunk                : 100\n",
      "scores_chunk              : 100\n",
      "question_chunk_embeddings : 100\n",
      "id_chunk[is_successful]   : 100\n",
      "Starting: 2 of 10 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99f69dd4c294977a91eda4fb6c0ae19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags_chunk                : 100\n",
      "scores_chunk              : 100\n",
      "question_chunk_embeddings : 100\n",
      "id_chunk[is_successful]   : 100\n",
      "Starting: 3 of 10 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0b905a4f2c44ccae8a9cb1d4740568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags_chunk                : 100\n",
      "scores_chunk              : 100\n",
      "question_chunk_embeddings : 100\n",
      "id_chunk[is_successful]   : 100\n",
      "Starting: 4 of 10 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beed79d588494398b3b4ce6167dfbb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags_chunk                : 100\n",
      "scores_chunk              : 100\n",
      "question_chunk_embeddings : 100\n",
      "id_chunk[is_successful]   : 100\n",
      "Starting: 5 of 10 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bede70ac1c74fcc9b98529f5ec0e783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags_chunk                : 100\n",
      "scores_chunk              : 100\n",
      "question_chunk_embeddings : 100\n",
      "id_chunk[is_successful]   : 100\n",
      "Starting: 6 of 10 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a46bd4bc444fa38df4c64adfec5cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags_chunk                : 100\n",
      "scores_chunk              : 100\n",
      "question_chunk_embeddings : 100\n",
      "id_chunk[is_successful]   : 100\n",
      "Starting: 7 of 10 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174a22a4277143aeaf4e43961cd4c844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags_chunk                : 100\n",
      "scores_chunk              : 100\n",
      "question_chunk_embeddings : 100\n",
      "id_chunk[is_successful]   : 100\n",
      "Starting: 8 of 10 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d550bab8002e4efea21063b19e2e7be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags_chunk                : 100\n",
      "scores_chunk              : 100\n",
      "question_chunk_embeddings : 100\n",
      "id_chunk[is_successful]   : 100\n",
      "Starting: 9 of 10 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7975788f97174bef959f9c3fe45ed39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags_chunk                : 100\n",
      "scores_chunk              : 100\n",
      "question_chunk_embeddings : 100\n",
      "id_chunk[is_successful]   : 100\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "\n",
    "BQ_NUM_ROWS = 1000 #50000\n",
    "BQ_CHUNK_SIZE = 100\n",
    "BQ_NUM_CHUNKS = math.ceil(BQ_NUM_ROWS / BQ_CHUNK_SIZE)\n",
    "\n",
    "START_CHUNK = 0\n",
    "\n",
    "# Create a rate limit of 300 requests per minute. Adjust this depending on your quota.\n",
    "API_CALLS_PER_SECOND = 300 / 60\n",
    "# According to the docs, each request can process 5 instances per request\n",
    "ITEMS_PER_REQUEST = 5\n",
    "\n",
    "print(f\"BQ_NUM_ROWS          : {BQ_NUM_ROWS}\")\n",
    "print(f\"BQ_CHUNK_SIZE        : {BQ_CHUNK_SIZE}\")\n",
    "print(f\"BQ_NUM_CHUNKS        : {BQ_NUM_CHUNKS}\")\n",
    "print(f\"API_CALLS_PER_SECOND : {API_CALLS_PER_SECOND}\")\n",
    "print(f\"ITEMS_PER_REQUEST    : {ITEMS_PER_REQUEST}\")\n",
    "\n",
    "\n",
    "# Loop through each generated dataframe, convert\n",
    "for i, df in tqdm(\n",
    "    enumerate(\n",
    "        query_bigquery_chunks(\n",
    "            max_rows=BQ_NUM_ROWS, \n",
    "            rows_per_chunk=BQ_CHUNK_SIZE, \n",
    "            start_chunk=START_CHUNK\n",
    "        )\n",
    "    ),\n",
    "    total=BQ_NUM_CHUNKS - START_CHUNK,\n",
    "    position=-1,\n",
    "    desc=\"Chunk of rows from BigQuery\",\n",
    "):\n",
    "    print(f\"Starting: {i} of {BQ_NUM_CHUNKS} loops\")\n",
    "    \n",
    "    # Create a unique output file for each chunk\n",
    "    chunk_path = embeddings_file_path.joinpath(\n",
    "        f\"{embeddings_file_path.stem}_{i+START_CHUNK}.json\"\n",
    "    )\n",
    "    with open(chunk_path, \"a\") as f:\n",
    "        id_chunk = df.id\n",
    "        scores_chunk = df.score\n",
    "        tags_chunk = df.tags_split\n",
    "\n",
    "        # Convert batch to embeddings\n",
    "        is_successful, question_chunk_embeddings = encode_text_to_embedding_batched(\n",
    "            # sentences=df.title_with_body,\n",
    "            sentences=df.title_with_body.tolist(), #[:500]\n",
    "            api_calls_per_second=API_CALLS_PER_SECOND,\n",
    "            batch_size=ITEMS_PER_REQUEST,\n",
    "        )\n",
    "\n",
    "        # Append to file\n",
    "        embeddings_formatted = [\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"id\": str(id),\n",
    "                    \"embedding\": [\n",
    "                        str(value) for value in embedding\n",
    "                    ],\n",
    "                    \"restricts\": [\n",
    "                        {\"namespace\": \"tags\", \"allow\": [str(tag)]}\n",
    "                    ],\n",
    "                    \"numeric_restricts\": [\n",
    "                        {\"namespace\": \"score\", \"value_int\": int(score)}\n",
    "                    ],\n",
    "                    \"crowding_tag\": str(_tag_crowd)\n",
    "                }\n",
    "            )\n",
    "            + \"\\n\"\n",
    "            # for id, embedding in zip(id_chunk[is_successful], question_chunk_embeddings)\n",
    "            for id, embedding, tag, score, _tag_crowd in zip(id_chunk[is_successful], question_chunk_embeddings, tags_chunk, scores_chunk, tags_chunk)\n",
    "        ]\n",
    "        f.writelines(embeddings_formatted)\n",
    "        \n",
    "        # print(f\"tags_chunk                : {len(tags_chunk)}\")\n",
    "        # print(f\"scores_chunk              : {len(scores_chunk)}\")\n",
    "        # print(f\"question_chunk_embeddings : {len(question_chunk_embeddings)}\")\n",
    "        # print(f\"id_chunk[is_successful]   : {len(id_chunk[is_successful])}\")\n",
    "\n",
    "        # Delete the DataFrame and any other large data structures\n",
    "        del df\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b4124-8bc1-4eb3-ab9b-8598504c1e10",
   "metadata": {},
   "source": [
    "#### example output\n",
    "\n",
    "a single `embeddings_formatted` entry should resemble:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"id\": \"67574726\", \n",
    "    \"embedding\": [\n",
    "        \"0.875, ..., 1.000\"\n",
    "    ], \n",
    "    \"restricts\": [\n",
    "        {\"namespace\": \"tags\", \"allow\": [\"c#\"]}\n",
    "    ], \n",
    "    \"numeric_restricts\": [\n",
    "        {\"namespace\": \"score\", \"value_int\": 1}\n",
    "    ],\n",
    "    \"crowding_tag\": \"c#\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "5f230e61-fd88-4a24-b847-536ceed98ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "18670\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings_formatted))\n",
    "print(len(embeddings_formatted[0]))\n",
    "# embeddings_formatted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c08a93b0-025d-4ef2-9af3-9944116d7343",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE_GCS_FOLDER: gs://vvs-vectorio-vpc1-hybrid-vertex/vvs-vectorio-vpc1/embedding_indexes/tmppkzjydtx/\n"
     ]
    }
   ],
   "source": [
    "REMOTE_GCS_FOLDER = f\"{BUCKET_URI}/{PREFIX}/embedding_indexes/{embeddings_file_path.stem}/\"\n",
    "print(f\"REMOTE_GCS_FOLDER: {REMOTE_GCS_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cf959860-dc17-4254-823d-2db0c6a592bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///var/tmp/tmppkzjydtx/tmppkzjydtx_0.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmppkzjydtx/tmppkzjydtx_1.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmppkzjydtx/tmppkzjydtx_2.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmppkzjydtx/tmppkzjydtx_3.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmppkzjydtx/tmppkzjydtx_4.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmppkzjydtx/tmppkzjydtx_5.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmppkzjydtx/tmppkzjydtx_6.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmppkzjydtx/tmppkzjydtx_7.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmppkzjydtx/tmppkzjydtx_8.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmppkzjydtx/tmppkzjydtx_9.json [Content-Type=application/json]...\n",
      "- [10/10 files][ 17.8 MiB/ 17.8 MiB] 100% Done                                  \n",
      "Operation completed over 10 objects/17.8 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! gsutil -m cp -r {embeddings_file_path}/* {REMOTE_GCS_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9e1986cc-4513-427a-b9c6-9961ac94b83d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://vvs-vectorio-vpc1-hybrid-vertex/vvs-vectorio-vpc1/embedding_indexes/tmppkzjydtx/tmppkzjydtx_0.json\n",
      "gs://vvs-vectorio-vpc1-hybrid-vertex/vvs-vectorio-vpc1/embedding_indexes/tmppkzjydtx/tmppkzjydtx_1.json\n",
      "gs://vvs-vectorio-vpc1-hybrid-vertex/vvs-vectorio-vpc1/embedding_indexes/tmppkzjydtx/tmppkzjydtx_2.json\n",
      "gs://vvs-vectorio-vpc1-hybrid-vertex/vvs-vectorio-vpc1/embedding_indexes/tmppkzjydtx/tmppkzjydtx_3.json\n",
      "gs://vvs-vectorio-vpc1-hybrid-vertex/vvs-vectorio-vpc1/embedding_indexes/tmppkzjydtx/tmppkzjydtx_4.json\n",
      "gs://vvs-vectorio-vpc1-hybrid-vertex/vvs-vectorio-vpc1/embedding_indexes/tmppkzjydtx/tmppkzjydtx_5.json\n",
      "gs://vvs-vectorio-vpc1-hybrid-vertex/vvs-vectorio-vpc1/embedding_indexes/tmppkzjydtx/tmppkzjydtx_6.json\n",
      "gs://vvs-vectorio-vpc1-hybrid-vertex/vvs-vectorio-vpc1/embedding_indexes/tmppkzjydtx/tmppkzjydtx_7.json\n",
      "gs://vvs-vectorio-vpc1-hybrid-vertex/vvs-vectorio-vpc1/embedding_indexes/tmppkzjydtx/tmppkzjydtx_8.json\n",
      "gs://vvs-vectorio-vpc1-hybrid-vertex/vvs-vectorio-vpc1/embedding_indexes/tmppkzjydtx/tmppkzjydtx_9.json\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $REMOTE_GCS_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60c68ee-c660-40b6-b10b-2dbd5fc71776",
   "metadata": {},
   "source": [
    "# Create Vertex Vector Search index and endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d37b9-58a7-4229-a46e-a914a0cf9750",
   "metadata": {},
   "source": [
    "## Create VS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "50820c8d-4ebc-4110-bac1-0e4e13938ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CREATE_NEW_VS_INDEX = True\n",
    "\n",
    "# !gcloud ai indexes list \\\n",
    "#   --project=$PROJECT_ID \\\n",
    "#   --region=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "543f9d21-b75c-48d3-bb8b-d58bb4d5a084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if using exsiting index\n",
    "if not CREATE_NEW_VS_INDEX:\n",
    "    EXISTING_INDEX_ID = \"..TODO..\"\n",
    "    EXISTING_INDEX_NAME = f'projects/{PROJECT_NUM}/locations/{REGION}/indexes/{EXISTING_INDEX_ID}'\n",
    "    print(f\"EXISTING_INDEX_NAME  : {EXISTING_INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "093fd1fd-d9b7-4d4e-83f5-c1fb2d03af41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX_NEIGHBORS          : 150\n",
      "DISTANCE_MEASURE          : DOT_PRODUCT_DISTANCE\n",
      "LEAF_NODE_EMB_COUNT       : 500\n",
      "LEAF_NODES_SEARCH_PERCENT : 80\n",
      "DIMENSIONS                : 768\n",
      "DISPLAY_NAME              : soverflow_vvs_vectorio_vpc1\n",
      "DESCRIPTION               : sample index for vectorio demo\n"
     ]
    }
   ],
   "source": [
    "# ANN index config\n",
    "APPROX_NEIGHBORS           = 150\n",
    "DISTANCE_MEASURE           = \"DOT_PRODUCT_DISTANCE\"\n",
    "LEAF_NODE_EMB_COUNT        = 500\n",
    "LEAF_NODES_SEARCH_PERCENT  = 80\n",
    "# DIMENSIONS                 = 768\n",
    "INDEX_UPDATE_METHOD        = 'batch_update' # accepts: 'batch_update' | 'stream_update'\n",
    "\n",
    "DISPLAY_NAME = f\"soverflow_{PREFIX}\".replace(\"-\",\"_\")\n",
    "DESCRIPTION = \"sample index for vectorio demo\"\n",
    "\n",
    "print(f\"APPROX_NEIGHBORS          : {APPROX_NEIGHBORS}\")\n",
    "print(f\"DISTANCE_MEASURE          : {DISTANCE_MEASURE}\")\n",
    "print(f\"LEAF_NODE_EMB_COUNT       : {LEAF_NODE_EMB_COUNT}\")\n",
    "print(f\"LEAF_NODES_SEARCH_PERCENT : {LEAF_NODES_SEARCH_PERCENT}\")\n",
    "print(f\"DIMENSIONS                : {DIMENSIONS}\")\n",
    "print(f\"INDEX_UPDATE_METHOD       : {INDEX_UPDATE_METHOD}\")\n",
    "print(f\"DISPLAY_NAME              : {DISPLAY_NAME}\")\n",
    "print(f\"DESCRIPTION               : {DESCRIPTION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a3c622c1-43e7-442f-afb3-43a4eaee4360",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISPLAY_NAME        : soverflow_vvs_vectorio_vpc1\n",
      "check display_name  : soverflow_vvs_vectorio_vpc1\n",
      "\n",
      "INDEX_RESOURCE_NAME : projects/934903580331/locations/us-central1/indexes/7417608906186162176\n"
     ]
    }
   ],
   "source": [
    "if CREATE_NEW_VS_INDEX:\n",
    "    \n",
    "    tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "        display_name=DISPLAY_NAME,\n",
    "        contents_delta_uri=REMOTE_GCS_FOLDER,\n",
    "        dimensions=DIMENSIONS,\n",
    "        approximate_neighbors_count=APPROX_NEIGHBORS,\n",
    "        distance_measure_type=DISTANCE_MEASURE,\n",
    "        leaf_node_embedding_count=LEAF_NODE_EMB_COUNT,\n",
    "        leaf_nodes_to_search_percent=LEAF_NODES_SEARCH_PERCENT,\n",
    "        description=DESCRIPTION,\n",
    "        index_update_method=INDEX_UPDATE_METHOD,\n",
    "        sync=True,\n",
    "        labels={\n",
    "            \"prefix\": f'{PREFIX}',\n",
    "        },\n",
    "    )\n",
    "else:\n",
    "    tree_ah_index = aiplatform.MatchingEngineIndex(EXISTING_INDEX_NAME)\n",
    "    \n",
    "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
    "\n",
    "print(f\"DISPLAY_NAME        : {DISPLAY_NAME}\")\n",
    "print(f\"check display_name  : {tree_ah_index.display_name}\\n\")\n",
    "print(f\"INDEX_RESOURCE_NAME : {INDEX_RESOURCE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04bbdf3-a45d-472a-a89c-c5db656ed1e1",
   "metadata": {},
   "source": [
    "*list all indexes:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "2da7a224-0188-426c-8f8e-5d472282bdac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.cloud.aiplatform.matching_engine.matching_engine_index.MatchingEngineIndex"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list_of_indices = tree_ah_index.list()\n",
    "# list_of_indices[0]\n",
    "# list_of_indices\n",
    "# type(list_of_indices[0])\n",
    "list_of_indices[0].resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc4c4df-dffe-486f-b732-a793ac3ac5e2",
   "metadata": {},
   "source": [
    "*Using the resource name, you can retrieve an existing MatchingEngineIndex:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f0b15e04-df33-4d15-b1b0-0ebc79d8a417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d429ac-38d5-4aad-8a65-ccb574950765",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Troubleshooting\n",
    "\n",
    "If index creation fails, grab `OPERATION_ID` and `FAILED_INDEX_ID` from the operation resource name in the error message, for example:\n",
    "\n",
    "> `Please check the details in the metadata of operation: projects/934903580331/locations/us-central1/indexes/FAILED_INDEX_ID/operations/OPERATION_ID.`\n",
    "\n",
    "Then, use `gcloud ai operations describe` to get the error details:\n",
    "\n",
    "```\n",
    "!gcloud ai operations describe $OPERATION_ID \\\n",
    "    --index=$FAILED_INDEX_ID \\\n",
    "    --project=$PROJECT_ID \\\n",
    "    --region=$REGION\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "19e45ce9-6b7d-416c-a1ae-c1306cad2a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OPERATION_ID    = \"2710742495469240320\"\n",
    "# FAILED_INDEX_ID = \"4846053518957608960\"\n",
    "\n",
    "# !gcloud ai operations describe $OPERATION_ID \\\n",
    "#     --index=$FAILED_INDEX_ID \\\n",
    "#     --project=$PROJECT_ID \\\n",
    "#     --region=$REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c666049-67ed-444a-b992-9dc027688ed8",
   "metadata": {},
   "source": [
    "## Create VS Index Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0a8fe71c-389e-40b8-8b67-5587b1f52875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CREATE_NEW_VS_INDEX_ENDPOINT = True\n",
    "\n",
    "# !gcloud ai index-endpoints list \\\n",
    "#   --project=$PROJECT_ID \\\n",
    "#   --region=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "89750e14-99ea-44e7-b6db-e8555b734be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if using exsiting index endpoint\n",
    "if not CREATE_NEW_VS_INDEX_ENDPOINT:\n",
    "    EXISTING_ENDPOINT_ID = \"..TODO..\"\n",
    "    EXISTING_ENDPOINT_NAME = f'projects/{PROJECT_NUM}/locations/{REGION}/indexEndpoints/{EXISTING_ENDPOINT_ID}'\n",
    "    print(f\"EXISTING_ENDPOINT_NAME  : {EXISTING_ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "350805a0-bd2c-4ba2-b05b-69995760d380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDPOINT_DISPLAY_NAME : soverflow_vvs_vectorio_vpc1_endpoint\n",
      "ENDPOINT_DESCRIPTION  : index endpoint for vectorio demo\n",
      "USE_PUBLIC_ENDPOINTS  : False\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT_DISPLAY_NAME = f'{DISPLAY_NAME}_endpoint'\n",
    "ENDPOINT_DESCRIPTION  = \"index endpoint for vectorio demo\"\n",
    "\n",
    "# USE_PUBLIC_ENDPOINTS  = False\n",
    "\n",
    "print(f\"ENDPOINT_DISPLAY_NAME : {ENDPOINT_DISPLAY_NAME}\")\n",
    "print(f\"ENDPOINT_DESCRIPTION  : {ENDPOINT_DESCRIPTION}\")\n",
    "print(f\"USE_PUBLIC_ENDPOINTS  : {USE_PUBLIC_ENDPOINTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b58d8f91-eec4-41be-88e1-8a470384306a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDPOINT_DISPLAY_NAME  : soverflow_vvs_vectorio_vpc1_endpoint\n",
      "check display_name     : soverflow_vvs_vectorio_vpc1_endpoint\n",
      "\n",
      "VPC_NETWORK_FULL       : projects/934903580331/global/networks/ucaip-haystack-vpc-network\n"
     ]
    }
   ],
   "source": [
    "if CREATE_NEW_VS_INDEX_ENDPOINT:\n",
    "    \n",
    "    my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=ENDPOINT_DISPLAY_NAME,\n",
    "        description=ENDPOINT_DESCRIPTION,\n",
    "        network=VPC_NETWORK_FULL,                    # if not USE_PUBLIC_ENDPOINTS else None,\n",
    "        public_endpoint_enabled=USE_PUBLIC_ENDPOINTS,\n",
    "        sync=True,\n",
    "        labels={\n",
    "            \"prefix\": f'{PREFIX}',\n",
    "        },\n",
    "    )\n",
    "else:\n",
    "    my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(EXISTING_ENDPOINT_NAME)\n",
    "    \n",
    "ENDPOINT_RESOURCE_NAME = my_index_endpoint.resource_name\n",
    "\n",
    "print(f\"ENDPOINT_DISPLAY_NAME  : {ENDPOINT_DISPLAY_NAME}\")\n",
    "print(f\"check display_name     : {my_index_endpoint.display_name}\\n\")\n",
    "print(f\"VPC_NETWORK_FULL       : {VPC_NETWORK_FULL}\")\n",
    "print(f\"check network name     : {my_index_endpoint.network}\\n\")\n",
    "print(f\"ENDPOINT_RESOURCE_NAME : {ENDPOINT_RESOURCE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "185236c8-3292-4d63-8e6f-da64cda4e2b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDPOINT_RESOURCE_NAME : projects/934903580331/locations/us-central1/indexEndpoints/4440729552494264320\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT_RESOURCE_NAME = my_index_endpoint.resource_name\n",
    "print(f\"ENDPOINT_RESOURCE_NAME : {ENDPOINT_RESOURCE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd309f-ca04-4b4b-818c-a990ce258b5e",
   "metadata": {},
   "source": [
    "## Deploy Indexes\n",
    "\n",
    "* [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/matching_engine/matching_engine_index_endpoint.py#L822)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "02de86f2-c272-4e28-902d-78812daac8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEPLOY_NEW_VS_INDEX = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ccb6d9ca-8561-446b-afaa-1dc64ee80fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if using exsiting deployed index\n",
    "if not DEPLOY_NEW_VS_INDEX:\n",
    "    EXISTING_DEPLOYED_INDEX_ID = \"..TODO..\"\n",
    "    EXISTING_DEPLOYED_INDEX_NAME = f'projects/{PROJECT_NUM}/locations/{REGION}/indexEndpoints/{EXISTING_DEPLOYED_INDEX_ID}'\n",
    "    print(f\"EXISTING_DEPLOYED_INDEX_NAME  : {EXISTING_DEPLOYED_INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4f0adcf2-3d1f-4894-87d3-1e7c51d7a3ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPLOYED_INDEX_ID : deployed_20240125_190236\n",
      "MIN_REPLICAS      : 1\n",
      "MAX_REPLICAS      : 1\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "DEPLOYED_INDEX_ID = f'deployed_{TIMESTAMP}'.replace(\"-\",\"_\")\n",
    "# MACHINE_TYPE = \"XXXX\"\n",
    "MIN_REPLICAS = 1\n",
    "MAX_REPLICAS = 1\n",
    "\n",
    "print(f\"DEPLOYED_INDEX_ID : {DEPLOYED_INDEX_ID}\")\n",
    "print(f\"MIN_REPLICAS      : {MIN_REPLICAS}\")\n",
    "print(f\"MAX_REPLICAS      : {MAX_REPLICAS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "34d9fae9-1e9b-4080-b8df-3080d2f26868",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPLOYED_INDEX_RESOURCE_NAME : projects/934903580331/locations/us-central1/indexEndpoints/4440729552494264320\n",
      "DEPLOYED_INDEX_DISPLAY_NAME  : soverflow_vvs_vectorio_vpc1_endpoint\n"
     ]
    }
   ],
   "source": [
    "if DEPLOY_NEW_VS_INDEX:\n",
    "    \n",
    "    deployed_index = my_index_endpoint.deploy_index(\n",
    "        index=tree_ah_index, \n",
    "        deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "        min_replica_count=MIN_REPLICAS,\n",
    "        max_replica_count=MAX_REPLICAS,\n",
    "        \n",
    "    )\n",
    "    \n",
    "else:\n",
    "    deployed_index = aiplatform.MatchingEngineIndexEndpoint(EXISTING_DEPLOYED_INDEX_NAME)\n",
    "\n",
    "DEPLOYED_INDEX_RESOURCE_NAME = deployed_index.resource_name\n",
    "DEPLOYED_INDEX_DISPLAY_NAME  = deployed_index.display_name\n",
    "\n",
    "print(f\"DEPLOYED_INDEX_RESOURCE_NAME : {DEPLOYED_INDEX_RESOURCE_NAME}\")\n",
    "print(f\"DEPLOYED_INDEX_DISPLAY_NAME  : {DEPLOYED_INDEX_DISPLAY_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "163313aa-f0e0-49ac-a732-a898b02a09bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployed indexes on the index endpoint:\n",
      "    deployed_20240125_190236\n"
     ]
    }
   ],
   "source": [
    "print(f\"Deployed indexes on the index endpoint:\")\n",
    "for d in my_index_endpoint.deployed_indexes:\n",
    "    print(f\"    {d.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "06f4d6e9-bd07-4a97-be3b-35245f7cb6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPLOYED_INDEX_ID_TEST : deployed_20240125_190236\n"
     ]
    }
   ],
   "source": [
    "DEPLOYED_INDEX_ID_TEST = deployed_index.deployed_indexes[0].id\n",
    "print(f\"DEPLOYED_INDEX_ID_TEST : {DEPLOYED_INDEX_ID_TEST}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f43da8b-3b02-4097-8d34-75dd3e6698d5",
   "metadata": {},
   "source": [
    "### Confirm matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "58c9e617-2ae4-46cc-969c-c4ba95312c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 1000, Actual: 1000\n"
     ]
    }
   ],
   "source": [
    "number_of_vectors = sum(\n",
    "    aiplatform.MatchingEngineIndex(\n",
    "        deployed_index.index\n",
    "    )._gca_resource.index_stats.vectors_count\n",
    "    for deployed_index in my_index_endpoint.deployed_indexes\n",
    ")\n",
    "\n",
    "print(f\"Expected: {BQ_NUM_ROWS}, Actual: {number_of_vectors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c7a227-6130-4e04-ac1c-8ade3a3bed9b",
   "metadata": {},
   "source": [
    "## Create online queries\n",
    "\n",
    "After you build your indexes, you may query against the deployed index to find nearest neighbors.\n",
    "\n",
    "Note: For the `DOT_PRODUCT_DISTANCE` distance type, the \"distance\" property returned with each MatchNeighbor actually refers to the similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7e60c1a6-d0df-405b-b7c0-c6b1ce0a90af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_embeddings = encode_texts_to_embeddings(sentences=[\"Install GPU for Tensorflow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "93ac31c1-00c1-413e-9a5b-043ead1577eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN latency: 0.0129 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "NUM_NEIGHBOURS = 10\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "response = my_index_endpoint.find_neighbors(\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    queries=test_embeddings,\n",
    "    num_neighbors=NUM_NEIGHBOURS,\n",
    "    return_full_datapoint=True,\n",
    ")\n",
    "\n",
    "elapsed_ann_time = time.time() - start\n",
    "elapsed_ann_time = round(elapsed_ann_time, 4)\n",
    "print(f'ANN latency: {elapsed_ann_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "415b2b9f-948d-47a4-be9f-3c0ad58ae8dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='43070568', distance=0.7574796676635742),\n",
       "  MatchNeighbor(id='54122858', distance=0.7128270864486694),\n",
       "  MatchNeighbor(id='53843711', distance=0.7045555114746094),\n",
       "  MatchNeighbor(id='56801148', distance=0.6956605911254883),\n",
       "  MatchNeighbor(id='45467758', distance=0.6887144446372986),\n",
       "  MatchNeighbor(id='45366523', distance=0.6812765598297119),\n",
       "  MatchNeighbor(id='61365790', distance=0.6766673922538757),\n",
       "  MatchNeighbor(id='65438932', distance=0.664444088935852),\n",
       "  MatchNeighbor(id='58616134', distance=0.663773238658905),\n",
       "  MatchNeighbor(id='54006694', distance=0.6581679582595825)]]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "444ff335-0d46-4294-94ed-d6649195c56c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN latency: 0.0137 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "NUM_NEIGHBOURS = 10\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "response = my_index_endpoint.find_neighbors(\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    queries=test_embeddings,\n",
    "    num_neighbors=NUM_NEIGHBOURS,\n",
    "    return_full_datapoint=False,\n",
    ")\n",
    "\n",
    "elapsed_ann_time = time.time() - start\n",
    "elapsed_ann_time = round(elapsed_ann_time, 4)\n",
    "print(f'ANN latency: {elapsed_ann_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "555b219a-334f-441f-84b7-b3bc3b62a1e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='43070568', distance=0.7574796676635742),\n",
       "  MatchNeighbor(id='54122858', distance=0.7128270864486694),\n",
       "  MatchNeighbor(id='53843711', distance=0.7045555114746094),\n",
       "  MatchNeighbor(id='56801148', distance=0.6956605911254883),\n",
       "  MatchNeighbor(id='45467758', distance=0.6887144446372986),\n",
       "  MatchNeighbor(id='45366523', distance=0.6812765598297119),\n",
       "  MatchNeighbor(id='61365790', distance=0.6766673922538757),\n",
       "  MatchNeighbor(id='65438932', distance=0.664444088935852),\n",
       "  MatchNeighbor(id='58616134', distance=0.663773238658905),\n",
       "  MatchNeighbor(id='54006694', distance=0.6581679582595825)]]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cd96e2b6-1768-47ac-9cd8-7ed036b3c54d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stackoverflow.com/questions/43070568\n",
      "https://stackoverflow.com/questions/54122858\n",
      "https://stackoverflow.com/questions/53843711\n",
      "https://stackoverflow.com/questions/56801148\n",
      "https://stackoverflow.com/questions/45467758\n",
      "https://stackoverflow.com/questions/45366523\n",
      "https://stackoverflow.com/questions/61365790\n",
      "https://stackoverflow.com/questions/65438932\n",
      "https://stackoverflow.com/questions/58616134\n",
      "https://stackoverflow.com/questions/54006694\n"
     ]
    }
   ],
   "source": [
    "for match_index, neighbor in enumerate(response[0]):\n",
    "    print(f\"https://stackoverflow.com/questions/{neighbor.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a0a91-f1cc-4d95-8439-d97214274276",
   "metadata": {},
   "source": [
    "### Retrieving metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "c68463ad-0981-4156-b8dc-5b9e9c22db0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crowding_tag       : crowding_attribute: \"6395101720579670463\"\n",
      "\n",
      "crowding_attribute : 6395101720579670463\n",
      "datapoint_id       : 54122858\n",
      "restricts          : [namespace: \"tags\"\n",
      "allow_list: \"machine-learning\"\n",
      "]\n",
      "allow_list         : ['machine-learning']\n",
      "deny_list          : []\n",
      "namespace          : tags\n"
     ]
    }
   ],
   "source": [
    "read_response = my_index_endpoint.read_index_datapoints(\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID, \n",
    "    ids= [\"43070568\", \"54122858\"],\n",
    ")\n",
    "# read_response\n",
    "print(f\"crowding_tag       : {read_response[0].crowding_tag}\")\n",
    "print(f\"crowding_attribute : {read_response[0].crowding_tag.crowding_attribute}\")\n",
    "print(f\"datapoint_id       : {read_response[0].datapoint_id}\")\n",
    "print(f\"restricts          : {read_response[0].restricts}\")\n",
    "print(f\"allow_list         : {read_response[0].restricts[0].allow_list}\")\n",
    "print(f\"deny_list          : {read_response[0].restricts[0].deny_list}\")\n",
    "print(f\"namespace          : {read_response[0].restricts[0].namespace}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ecfb75-512d-4545-a484-9a82595504a5",
   "metadata": {},
   "source": [
    "# Clean-up\n",
    "\n",
    "> TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a3b1cb-2632-4f7c-9e64-e6948f324e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# delete_bucket = False\n",
    "\n",
    "# # Force undeployment of indexes and delete endpoint\n",
    "# my_index_endpoint.delete(force=True)\n",
    "\n",
    "# # Delete indexes\n",
    "# tree_ah_index.delete()\n",
    "\n",
    "# if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "#     ! gsutil rm -rf {BUCKET_URI}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m115"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
